{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a chat bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Will have to do :\n",
    "install python;\n",
    "install jupyter notebook\n",
    "do pip install on alot of things!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Import stuff\n",
    "import nltk, re, pprint\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import random\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = 'leaves.txt'\n",
    "\n",
    "# leaves_data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Stem words\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get contents from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_content(filename):\n",
    "    test_doc = os.path.join(filename)\n",
    "    with open(test_doc, 'r') as content_file:\n",
    "        lines = csv.reader(content_file,delimiter='|')\n",
    "        res = [x for x in lines if len(x) == 3]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = get_content(file_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Greetings'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This data is a list\n",
    "data[1]\n",
    "data[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = \"The big brown fox jumped over a lazy dog.\"\n",
    "sentence2 = \"Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefgh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the big brown fox jumped over a lazy dog.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert sentence to lower case\n",
    "'This' == 'this'\n",
    "print('AbcdEFgH'.lower())\n",
    "sentence.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'big', 'brown', 'fox', 'jumped', 'over', 'a', 'lazy', 'dog']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract individual words\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'big', 'brown', 'fox', 'jumped', 'lazy', 'dog']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words = [w for w in tokens if not w in stopwords.words('english')]\n",
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['big', 'brown', 'fox', 'jumped', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "preprocessed_sentence = preprocess(sentence)\n",
    "print(preprocessed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('big', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumped', 'VBD'), ('lazy', 'JJ'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "tags = nltk.pos_tag(preprocessed_sentence)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting only Nouns and Verb nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(sentences):\n",
    "    features = []\n",
    "    for tagged_word in sentences:\n",
    "        word, tag = tagged_word\n",
    "        if tag=='NN' or tag == 'VBN' or tag == 'NNS' or tag == 'VBP' or tag == 'RB' or tag == 'VBZ' or tag == 'VBG' or tag =='PRP' or tag == 'JJ':\n",
    "            features.append(word)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['big', 'brown', 'fox', 'lazy', 'dog']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Lemmatize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cactus'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "lmtzr.lemmatize('cacti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'willing'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmtzr.lemmatize('willing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foot'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmtzr.lemmatize('feet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stemmed'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmtzr.lemmatize('stemmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_for_stemming = ['stem', 'stemming', 'stemmed', 'stemmer', 'stems','feet','willing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stem', 'stem', 'stem', 'stemmer', 'stem', 'feet', 'will']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[stemmer.stem(x) for x in words_for_stemming]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using porter stemmer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stem', 'stem', 'stem', 'stemmer', 'stem', 'feet', 'will']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "[stemmer.stem(x) for x in words_for_stemming]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_feature_set(sent_keys):\n",
    "#     return {'keywords': ' '.join(sent_keys)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "Extracting features from one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature(text):\n",
    "    words = preprocess(text)\n",
    "#     print('words: ',words)\n",
    "    tags = nltk.pos_tag(words)\n",
    "#     print('tags: ',tags)\n",
    "    extracted_features = extract_features(tags)#rename to extract keys based on tags\n",
    "#     print('Extracted features: ',extracted_features)\n",
    "    stemmed_words = [stemmer.stem(x) for x in extracted_features]\n",
    "#     print(stemmed_words)\n",
    "    # join with space\n",
    "#     return (\" \".join(stemmed_words))\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['big', 'brown', 'fox', 'lazi', 'dog']"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_feature(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parsing the whole document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_feature_from_doc(data):\n",
    "    result = []\n",
    "    corpus = []\n",
    "    for (text,category,answer) in data:\n",
    "#         corpus.append(text)\n",
    "#         print(corpus)\n",
    "        features = extract_feature(text)\n",
    "        corpus.append(features)\n",
    "        # features.append((sent_features, category))\n",
    "        result.append((\" \".join(features), answer))\n",
    "    return (result, sum(corpus,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_content(filename):\n",
    "    doc = os.path.join(filename)\n",
    "    with open(doc, 'r') as content_file:\n",
    "        lines = csv.reader(content_file,delimiter='|')\n",
    "        data = [x for x in lines if len(x) == 3]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = get_content(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_data, corpus = extract_feature_from_doc(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number option leav taken' 'number option leav alreadi taken'\n",
      " 'option leav taken' 'option leav alreadi taken' 'number option leav'\n",
      " 'number option leav' 'option leav count use' 'option leav count use'\n",
      " 'option leav count use' 'option leav count use']\n"
     ]
    }
   ],
   "source": [
    "features_data_with_labels = np.array(features_data)\n",
    "extracted_features_only = (features_data_with_labels[:,0])\n",
    "type(extracted_features_only)\n",
    "print(extracted_features_only[70:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'hi', 'hello', 'hi', 'hi']"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)\n",
    "vectorizer                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Following is an example of the corpus\n",
    "# corpus = [\n",
    "# ...     'This is the first document.',\n",
    "# ...     'This is the second second document.',\n",
    "# ...     'And the third one.',\n",
    "# ...     'Is this the first document?',\n",
    "# ... ]\n",
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello' 'hi hello' 'hi' 'hi' 'hi' 'hey' 'hello hi' 'hey' 'hey hi'\n",
      " 'hey hello' 'good morn' 'good afternoon' 'good even' 'good night' '_' '__'\n",
      " '' '' '' '' '' '' 'today' '' 'want help' 'need help' 'help' 'want help'\n",
      " 'want assist' 'help' 'name' 'tell name' 'name' 'great talk' 'great'\n",
      " 'thank help' 'thank' 'thank much' 'thank' 'thank much' 'mani type leav'\n",
      " 'type leav' 'type leav' 'type' 'leav type' 'mani leav taken'\n",
      " 'mani leav alreadi taken' 'mani annual leav' 'mani annual leav taken'\n",
      " 'mani annual leav alreadi taken' 'annual leav count taken'\n",
      " 'mani annual leav taken' 'number annual leav taken' 'annual leav taken'\n",
      " 'number annual leav alreadi taken' 'annual leav taken'\n",
      " 'annual leav alreadi taken' 'number annual leav taken'\n",
      " 'number annual leav' 'taken annual leav' 'annual leav'\n",
      " 'mani option leav taken' 'mani option leav' 'option leav taken'\n",
      " 'number option leav taken' 'option leav count taken'\n",
      " 'number option leav taken' 'number option leav taken'\n",
      " 'number option leav taken' 'mani option leav taken'\n",
      " 'number option leav taken' 'number option leav alreadi taken'\n",
      " 'option leav taken' 'option leav alreadi taken' 'number option leav'\n",
      " 'number option leav' 'option leav count use' 'option leav count use'\n",
      " 'option leav count use' 'option leav count use' 'option leav count taken'\n",
      " 'option leav count taken' 'option leav count taken' 'mani option leav'\n",
      " 'mani option leav' 'number option leav' 'option leav' 'mani leav'\n",
      " 'mani leav take' 'mani leav remain' 'remain leav' 'leav'\n",
      " 'tell leav balanc' 'remain leav' 'leav balanc' 'leav pend'\n",
      " 'annual leav count remain' 'mani annual leav' 'annual leav'\n",
      " 'annual leav balanc' 'annual leav' 'mani annual leav remain'\n",
      " 'annual leav remain' 'remain annual leav' 'annual leav remain'\n",
      " 'number annual leav remain' 'number annual leav' 'annual leav remain'\n",
      " 'annual leav count remain' 'annual leav count remain'\n",
      " 'annual leav count remain' 'annual leav count remain' 'annual leav balanc'\n",
      " 'annual leav balanc' 'annual leav' 'number annual leav remain'\n",
      " 'number annual leav remain' 'mani option leav remain' 'option leav remain'\n",
      " 'number option leav remain' 'mani option leav' 'mani option leav'\n",
      " 'option leav balanc' 'option leav' 'mani option leav take'\n",
      " 'option leav take' 'mani option leav' 'option leav balanc'\n",
      " 'option leav count remain' 'option leav' 'option leav'\n",
      " 'option leav balanc' 'option' 'option leav count remain'\n",
      " 'option leav count remain' 'option leav count remain'\n",
      " 'number option leav remain' 'number option leav remain'\n",
      " 'number option leav remain' 'number option leav' 'number option leav'\n",
      " 'mani carri forward leav' 'number carri forward leav'\n",
      " 'tell carri forward leav count' 'number forward leav'\n",
      " 'number forward leav' 'number forward leav'\n",
      " 'mani carri forward previou year' 'tell carri forward leav previou year'\n",
      " 'tell carri forward leav' 'tell carri forward leav' 'forward leav'\n",
      " 'carri forward leav' 'carri forward' 'previou year carri forward leav']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<155x38 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 431 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(extracted_features_only)\n",
    "X = vectorizer.fit_transform(extracted_features_only)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"This is a text document to analyze.\") == (['this', 'is', 'text', 'document', 'to', 'analyze'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__',\n",
       " 'afternoon',\n",
       " 'alreadi',\n",
       " 'annual',\n",
       " 'assist',\n",
       " 'balanc',\n",
       " 'carri',\n",
       " 'count',\n",
       " 'even',\n",
       " 'forward',\n",
       " 'good',\n",
       " 'great',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'leav',\n",
       " 'mani',\n",
       " 'morn',\n",
       " 'much',\n",
       " 'name',\n",
       " 'need',\n",
       " 'night',\n",
       " 'number',\n",
       " 'option',\n",
       " 'pend',\n",
       " 'previou',\n",
       " 'remain',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'talk',\n",
       " 'tell',\n",
       " 'thank',\n",
       " 'today',\n",
       " 'type',\n",
       " 'use',\n",
       " 'want',\n",
       " 'year']"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 38)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "sum(sum(X.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()[70:80,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('leav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !! words that were not seen in the training corpus will be completely ignored in future calls to the transform method\n",
    "\n",
    "# To do next - try Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. I am Dexter. I will serve your leave enquiries as of %(date)s\n"
     ]
    }
   ],
   "source": [
    "print(d[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the bag_of_words result with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-223-4a8612918f90>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-223-4a8612918f90>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    result = X.toarray + d[][1]\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# result = X.toarray + d[][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 107 µs, sys: 7 µs, total: 114 µs\n",
      "Wall time: 130 µs\n",
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Good Morning. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Good afternoon. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Good evening. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       "       'Good night. Take care.', \"I am sorry, I don't understand.\",\n",
       "       \"I am sorry, I don't understand.\",\n",
       "       \"I am sorry, I don't understand.\",\n",
       "       \"I am sorry, I don't understand.\",\n",
       "       \"I am sorry, I don't understand.\",\n",
       "       \"I am sorry, I don't understand.\",\n",
       "       \"I'm fine! Thank you. How can I help you?\",\n",
       "       \"I'm fine! Thank you. How can I help you?\",\n",
       "       \"I'm fine! Thank you. How can I help you?\",\n",
       "       'Thank you. How can I help you?', 'How can I help you?',\n",
       "       'How can I help you?', 'How can I help you?',\n",
       "       'Ok sir/madam. No problem. Have a nice day.',\n",
       "       'Ok sir/madam. No problem. Have a nice day.',\n",
       "       'Ok sir/madam. No problem. Have a nice day.',\n",
       "       'Your name is %(name)s', 'Your name is %(name)s',\n",
       "       'Your name is %(name)s',\n",
       "       \"It's glad to know that I have been helpful. Have a good day!\",\n",
       "       \"It's glad to know that I have been helpful. Have a good day!\",\n",
       "       \"It's glad to know that I have been helpful. Have a good day!\",\n",
       "       \"It's glad to know that I have been helpful. Have a good day!\",\n",
       "       \"It's glad to know that I have been helpful. Have a good day!\",\n",
       "       \"You're welcome!It's glad to know that I have been helpful. Have a good day!\",\n",
       "       \"It's glad to know that I have been helpful. Have a good day!\",\n",
       "       'Currently I know about two: annual and optional leaves.',\n",
       "       'Currently I know about two: annual and optional leaves.',\n",
       "       'Currently I know about two: annual and optional leaves.',\n",
       "       'Currently I know about two: annual and optional leaves.',\n",
       "       'Currently I know about two: annual and optional leaves.',\n",
       "       'You have used %(annual_leaves)s annual leaves.',\n",
       "       'You have used %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(annual_leaves)s annual leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have taken %(optional_leaves)s optional leaves.',\n",
       "       'You have %(rem_annual)s annual leaves left.',\n",
       "       'You have %(rem_annual)s annual leaves left.',\n",
       "       'You have %(rem_annual)s annual leaves left.',\n",
       "       'You have %(rem_annual)s annual leaves left.',\n",
       "       'You have %(rem_annual)s annual leaves left.',\n",
       "       'You have %(rem_annual)s annual leaves left.',\n",
       "       'You have %(rem_annual)s annual leaves left.',\n",
       "       'You have %(rem_annual)s annual leaves left.',\n",
       "       'You have %(rem_annual)s annual leaves left.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_annual)s annual leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(rem_optional)s optional leaves remaining.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.',\n",
       "       'You have %(carry_forward)s carry forward leaves.'], dtype=object)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment\n",
    "# import numpy as np\n",
    "%time temp = np.array(d)\n",
    "%time temp[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 µs, sys: 0 ns, total: 24 µs\n",
      "Wall time: 26 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Hello. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Good Morning. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Good afternoon. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Good evening. I am Dexter. I will serve your leave enquiries as of %(date)s',\n",
       " 'Good night. Take care.',\n",
       " \"I am sorry, I don't understand.\",\n",
       " \"I am sorry, I don't understand.\",\n",
       " \"I am sorry, I don't understand.\",\n",
       " \"I am sorry, I don't understand.\",\n",
       " \"I am sorry, I don't understand.\",\n",
       " \"I am sorry, I don't understand.\",\n",
       " \"I'm fine! Thank you. How can I help you?\",\n",
       " \"I'm fine! Thank you. How can I help you?\",\n",
       " \"I'm fine! Thank you. How can I help you?\",\n",
       " 'Thank you. How can I help you?',\n",
       " 'How can I help you?',\n",
       " 'How can I help you?',\n",
       " 'How can I help you?',\n",
       " 'Ok sir/madam. No problem. Have a nice day.',\n",
       " 'Ok sir/madam. No problem. Have a nice day.',\n",
       " 'Ok sir/madam. No problem. Have a nice day.',\n",
       " 'Your name is %(name)s',\n",
       " 'Your name is %(name)s',\n",
       " 'Your name is %(name)s',\n",
       " \"It's glad to know that I have been helpful. Have a good day!\",\n",
       " \"It's glad to know that I have been helpful. Have a good day!\",\n",
       " \"It's glad to know that I have been helpful. Have a good day!\",\n",
       " \"It's glad to know that I have been helpful. Have a good day!\",\n",
       " \"It's glad to know that I have been helpful. Have a good day!\",\n",
       " \"You're welcome!It's glad to know that I have been helpful. Have a good day!\",\n",
       " \"It's glad to know that I have been helpful. Have a good day!\",\n",
       " 'Currently I know about two: annual and optional leaves.',\n",
       " 'Currently I know about two: annual and optional leaves.',\n",
       " 'Currently I know about two: annual and optional leaves.',\n",
       " 'Currently I know about two: annual and optional leaves.',\n",
       " 'Currently I know about two: annual and optional leaves.',\n",
       " 'You have used %(annual_leaves)s annual leaves.',\n",
       " 'You have used %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(annual_leaves)s annual leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have taken %(optional_leaves)s optional leaves.',\n",
       " 'You have %(rem_annual)s annual leaves left.',\n",
       " 'You have %(rem_annual)s annual leaves left.',\n",
       " 'You have %(rem_annual)s annual leaves left.',\n",
       " 'You have %(rem_annual)s annual leaves left.',\n",
       " 'You have %(rem_annual)s annual leaves left.',\n",
       " 'You have %(rem_annual)s annual leaves left.',\n",
       " 'You have %(rem_annual)s annual leaves left.',\n",
       " 'You have %(rem_annual)s annual leaves left.',\n",
       " 'You have %(rem_annual)s annual leaves left.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_annual)s annual leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(rem_optional)s optional leaves remaining.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.',\n",
       " 'You have %(carry_forward)s carry forward leaves.']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment\n",
    "# asd= X.toarray() + d[:,1]\n",
    "%time list(list(zip(*d))[1]) # zip is faster!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = list(list(zip(*d))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "def train_using_decision_tree(training_data, test_data):\n",
    "    # Good results\n",
    "    classifier = DecisionTreeClassifier(training_data)\n",
    "    classifier_name = type(classifier).__name__\n",
    "    training_set_accuracy = classifier.accuracy(training_data)\n",
    "    test_set_accuracy = classifier.accuracy(test_data)\n",
    "    return classifier, classifier_name, training_set_accuracy, test_set_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## split data into train and test sets\n",
    "split_ratio = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(data, split_ratio):\n",
    "    random.shuffle(data)\n",
    "    data_length = len(data)\n",
    "    train_split = int(data_length * split_ratio)\n",
    "    return (data[:train_split]), (data[train_split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, test_data = split_dataset(, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier, classifier_name, test_set_accuracy, training_set_accuracy = train_using_decision_tree(training_data, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
